import torch
from torch import nn
from torch.utils.data import Dataset

from torchvision import datasets
from torchvision.transforms import ToTensor

import numpy as np


# super simple class that wraps a torch.Tensor inside a Dataset

class MyDataset(Dataset):
    def __init__(self, data):
        self.data = data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        return self.data[idx]


# Sigmoid activation with arbitrary steepness. Can be used in a network.

class Sigmoid(nn.Module):
    def __init__(self, k):
        super().__init__()
        self.k = k

    def forward(self, x):
        return torch.sigmoid(self.k * x)


# load mnist dataset and return a pytorch tensor containing train and test digits, without labels,
# with pixel intensities between 0 and 1.

def load_mnist():

    # load data
    training_data = datasets.MNIST(
        root="data",
        train=True,
        download=True,
        transform=ToTensor(),
    )
    test_data = datasets.MNIST(
        root="data",
        train=False,
        download=True,
        transform=ToTensor(),
    )

    # extract digits
    train = training_data.data
    test = test_data.data

    # flatten digits
    train = train.flatten(start_dim=1)
    test = test.flatten(start_dim=1)

    # merge train and test
    data = torch.cat((train, test), 0)

    # squeeze entries between 0.0 and 1.0
    data = (data / 255.0).to(torch.float32)

    return data


# generate a dataset of P random patterns lying on a D-dimensional manifold embedded in N-dimensional space.
# the patterns are generated by projecting a random D-dimensional binary vector in the N-dimensional space
# through a projection matrix, and applying a nonlinearity component-wise.

def hidden_manifold(
        N,
        D,
        P,
        sigma=Sigmoid(30),
        p=0.5,
        device='cpu',
        test=None,
):
    F = torch.randn((D, N), device=device)              # feature matrix
    probas = p * torch.ones((P, D), device=device)      # matrix of probabilities for binary patterns
    csi = torch.bernoulli(probas).to(device)            # random binary patterns
    data = torch.matmul(csi, F) / np.sqrt(D)            # compute activations for nonlinearity
    data = sigma(data)                                  # pass projected data through nonlinearity

    if test is None:
        return data

    probas = p * torch.ones((test, D), device=device)  # matrix of probabilities for binary patterns
    csi = torch.bernoulli(probas).to(device)  # random binary patterns
    test_data = torch.matmul(csi, F) / np.sqrt(D)  # compute activations for nonlinearity
    test_data = sigma(test_data)  # pass projected data through nonlinearity
    
    return data, test_data
